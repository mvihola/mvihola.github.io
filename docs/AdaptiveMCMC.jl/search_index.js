var documenterSearchIndex = {"docs":
[{"location":"step/#Step-sizes","page":"Step sizes","title":"Step sizes","text":"","category":"section"},{"location":"step/","page":"Step sizes","title":"Step sizes","text":"All adaptation algorithms are based on similar sequential stochastic gradient like (or Robbins-Monro) updates, which rely in decreasing step size or 'learning rate' sequence gamma_k.","category":"page"},{"location":"step/","page":"Step sizes","title":"Step sizes","text":"The AdaptiveMCMC.jl uses an abstract StepSize type. Each concrete subtype should have a method get(stepsize, k), which returns gamma_k corresponding to stepsize.","category":"page"},{"location":"step/","page":"Step sizes","title":"Step sizes","text":"The current implementation AdaptiveMCMC.jl implements essentially only the step size of the form:","category":"page"},{"location":"step/","page":"Step sizes","title":"Step sizes","text":"   gamma_k = c k^-eta","category":"page"},{"location":"step/","page":"Step sizes","title":"Step sizes","text":"where c0 and 12  etale 1 are the two parameters of the sequence. (The given range for eta ensures that sum_k eta_k = infty and sum_k eta_k^2 infty, which are desirable properties for the step size sequence...)","category":"page"},{"location":"step/","page":"Step sizes","title":"Step sizes","text":"PolynomialStepSize","category":"page"},{"location":"step/#AdaptiveMCMC.PolynomialStepSize","page":"Step sizes","title":"AdaptiveMCMC.PolynomialStepSize","text":"gamma = PolynomialStepSize(eta::AbstractFloat, [c::AbstractFloat=1.0]))\n\nConstructor for PolynomialStepSize.\n\nArguments\n\neta: The step size exponent, should be within (1/2,1].\nc: Scaling factor; default 1.0.\n\n\n\n\n\n","category":"type"},{"location":"step/","page":"Step sizes","title":"Step sizes","text":"There is also a variant of the PolynomialStepSize for the RAM: ","category":"page"},{"location":"step/","page":"Step sizes","title":"Step sizes","text":"   gamma_k = min12 d k^-eta","category":"page"},{"location":"step/","page":"Step sizes","title":"Step sizes","text":"where d is the state dimension. The RAM step size can be constructed as follows:","category":"page"},{"location":"step/","page":"Step sizes","title":"Step sizes","text":"RAMStepSize","category":"page"},{"location":"step/#AdaptiveMCMC.RAMStepSize","page":"Step sizes","title":"AdaptiveMCMC.RAMStepSize","text":"gamma = RAMStepSize(eta::AbstractFloat, d::Int)\n\nConstructor for RAM step size.\n\nArguments\n\neta: The step size exponent, should be within (1/2,1].\nd: State dimension.\n\n\n\n\n\n","category":"type"},{"location":"examples/#Further-examples","page":"Further examples","title":"Further examples","text":"","category":"section"},{"location":"examples/","page":"Further examples","title":"Further examples","text":"Here are some further examples how the package can be used.","category":"page"},{"location":"examples/#Custom-sampler","page":"Further examples","title":"Custom sampler","text":"","category":"section"},{"location":"examples/","page":"Further examples","title":"Further examples","text":"The package provides simple building blocks which you can use within a 'custom' MCMC sampler. Here is an example:","category":"page"},{"location":"examples/","page":"Further examples","title":"Further examples","text":"using AdaptiveMCMC\n\n# Sampler in R^d\nfunction mySampler(log_p, n, x0)\n\n    # Initialise random walk sampler state: r.x current state, r.y proposal\n    r = RWMState(x0)\n\n    # Initialise Adaptive Metropolis state (with default parameters)\n    s = AdaptiveMetropolis(x0)\n    # Other adaptations are: AdaptiveScalingMetropolis,\n    # AdaptiveScalingWithinAdaptiveMetropolis, and RobustAdaptiveMetropolis\n\n    X = zeros(eltype(x0), length(x0), n) # Allocate output storage\n    p_x = log_p(r.x)                     # = log_p(x0); the initial log target\n    for k = 1:n\n\n        # Draw new proposal r.x -> r.y:\n        draw!(r, s)\n\n        p_y = log_p(r.y)                      # Calculate log target at proposal\n        alpha = min(one(p_x), exp(p_y - p_x)) # The Metropolis acceptance probability\n\n        if rand() <= alpha\n            p_x = p_y\n\n            # This 'accepts', or interchanges r.x <-> r.y:\n            # (NB: do not do r.x = r.y; these are (pointers to) vectors!)\n            accept!(r)\n        end\n\n        # Do the adaptation update:\n        adapt!(s, r, alpha, k)\n\n        X[:,k] = r.x   # Save the current sample\n     end\n    X\nend\n\n# Standard normal target for testing\nnormal_log_p(x) = -mapreduce(e->e*e, +, x)/2\n\n# Run 1M iterations of the sampler targetting 30d standard Normal:\nX = mySampler(normal_log_p, 1_000_000, zeros(30))","category":"page"},{"location":"examples/#Using-custom-'local-move'-kernel-within-adaptive-parallel-tempering","page":"Further examples","title":"Using custom 'local move' kernel within adaptive parallel tempering","text":"","category":"section"},{"location":"adapt/#Adaptation-state","page":"Adaptation state","title":"Adaptation state","text":"","category":"section"},{"location":"adapt/","page":"Adaptation state","title":"Adaptation state","text":"The state of each adaptive algorithms is encapsulated to a subtype of abstract type AdaptState. Each adaptive algorithm implements two methods","category":"page"},{"location":"adapt/","page":"Adaptation state","title":"Adaptation state","text":"draw!(::RWMState, ::AdaptState)\nadapt!(::AdaptState, ::RWMState, α)","category":"page"},{"location":"adapt/","page":"Adaptation state","title":"Adaptation state","text":"The draw! method forms proposals of the form","category":"page"},{"location":"adapt/","page":"Adaptation state","title":"Adaptation state","text":"Y_k = X_k-1 + S_k-1 U_k quad U_k sim q","category":"page"},{"location":"adapt/","page":"Adaptation state","title":"Adaptation state","text":"where q is the 'prototype proposal' as discussed in Random walk sampler state, and the form of the 'shape' matrix factor S_k-1 depends on the chosen adaptive algorithm.","category":"page"},{"location":"adapt/","page":"Adaptation state","title":"Adaptation state","text":"The adapt! method updates the adapted state, based on the state of the random walk sampler. Some of the adaptation algorithms use the third argument of adapt!: the acceptance probability alphain01.","category":"page"},{"location":"adapt/#Adaptive-Metropolis","page":"Adaptation state","title":"Adaptive Metropolis","text":"","category":"section"},{"location":"adapt/","page":"Adaptation state","title":"Adaptation state","text":"AdaptiveMetropolis","category":"page"},{"location":"adapt/#AdaptiveMCMC.AdaptiveMetropolis","page":"Adaptation state","title":"AdaptiveMCMC.AdaptiveMetropolis","text":"r = AdaptiveMetropolis(x0; kwargs)\nr = AdaptiveMetropolis(x0, [scale, [step]])\n\nConstructor for AdaptiveMetropolis state.\n\nArguments\n\nx0: The initial state vector\n\nKeyword arguments\n\nscale: Scaling parameter; default 2.38/sqrt(d) where d is dimension.\nstep: Step size object; default PolynomialStepSize(1.0)\nS_init: Initial proposal shape Cholesky factor; default identity_cholesky(x0)\n\nIf s is RWMState, then proposal samples may be drawn calling  draw!(s, r) and adaptation is performed with adapt!(r, s) or  adapt_rb!(r, s, α).\n\n\n\n\n\n","category":"type"},{"location":"adapt/","page":"Adaptation state","title":"Adaptation state","text":"This is the seminal Adaptive Metropolis (AM) algorithm of Haario, Saksman & Tamminen (2001), where the proposal increment shape is","category":"page"},{"location":"adapt/","page":"Adaptation state","title":"Adaptation state","text":"S_k-1 + s_d L_k-1","category":"page"},{"location":"adapt/","page":"Adaptation state","title":"Adaptation state","text":"where s_d is a fixed scaling defaulting to s_d = frac238sqrtd, where d is the dimension, and L_k-1 is the Cholesky factor of estimated covariance matrix.","category":"page"},{"location":"adapt/","page":"Adaptation state","title":"Adaptation state","text":"The covariance matrix is estimated using the recursive Robbins-Monro stochastic approximation update of Andrieu & Moulines (2006), that is,","category":"page"},{"location":"adapt/","page":"Adaptation state","title":"Adaptation state","text":"beginaligned\nmu_k = (1-gamma_k)mu_k-1 + gamma_k X_k \nSigma_k = (1-gamma_k)Sigma_k-1 + gamma_k (X_k - mu_k-1)(X_k - mu_k-1)^T\nendaligned","category":"page"},{"location":"adapt/","page":"Adaptation state","title":"Adaptation state","text":"where gamma_k is one of the Step sizes.","category":"page"},{"location":"adapt/","page":"Adaptation state","title":"Adaptation state","text":"In fact, the Sigma_k fators are not calculated directly as given above, but their Cholesky factors are updated sequentially, using rank-1 updates. This is more efficient, as calculating a full Cholesky factor is O(d^3) but rank-1 updates are O(d^2).","category":"page"},{"location":"adapt/","page":"Adaptation state","title":"Adaptation state","text":"The empirical covariances Sigma_k of the AM converge to the true target covariance (under technical conditions).","category":"page"},{"location":"adapt/#Robust-adaptive-Metropolis","page":"Adaptation state","title":"Robust adaptive Metropolis","text":"","category":"section"},{"location":"adapt/","page":"Adaptation state","title":"Adaptation state","text":"RobustAdaptiveMetropolis","category":"page"},{"location":"adapt/#AdaptiveMCMC.RobustAdaptiveMetropolis","page":"Adaptation state","title":"AdaptiveMCMC.RobustAdaptiveMetropolis","text":"r = RobustAdaptiveMetropolis(x0; kwargs)\nr = RobustAdaptiveMetropolis(x0, [acc_target, [step]])\n\nConstructor for RobustAdaptiveMetropolis state.\n\nArguments\n\nx0: The initial state vector\n\nKeyword arguments\n\nacc_target: Desired mean accept rate; default 0.234.\nstep: Step size object; default RAMStepSize(0.66,d) where d is state dimension.\nS_init: Initial proposal shape Cholesky factor; default identity_cholesky(x0)\n\nIf s is RWMState, then proposal samples may be drawn calling  draw!(s, r) and adaptation is performed with adapt!(r, s, α).\n\n\n\n\n\n","category":"type"},{"location":"adapt/","page":"Adaptation state","title":"Adaptation state","text":"This is the Robust Adaptive Metropolis (RAM) of Vihola, 2010. In this algorithm, the shape S_k is adapted directly by Cholesky rank-1 updates:","category":"page"},{"location":"adapt/","page":"Adaptation state","title":"Adaptation state","text":"S_k S_k^T = S_k-1 bigg( I + gamma_k (alpha_k - alpha_*) fracU_k U_k^T U_k ^2 bigg) S_k-1","category":"page"},{"location":"adapt/","page":"Adaptation state","title":"Adaptation state","text":"where alpha_k is the acceptance probability of the move X_k-1 to Y_k, and U_k is the 'prototype proposal' used when forming the proposal Y_k, and alpha_*in(01) is the desired acceptance rate, defaulting to 0234.","category":"page"},{"location":"adapt/","page":"Adaptation state","title":"Adaptation state","text":"In the case of finite-variance elliptically symmetric target distribution (and technical conditions), the shape parameter S_k converges to a Cholesky factor of a matrix which is proportional to the covariance. However, in general, the limiting shapes of the RAM and the AM can differ.","category":"page"},{"location":"adapt/","page":"Adaptation state","title":"Adaptation state","text":"The RAM seems to have empirical advantage over AM in certain cases, such as higher dimensions, but RAM is not directly applicable for instance with Pseudo-marginal algorithms.","category":"page"},{"location":"adapt/#Adaptive-scaling-Metropolis","page":"Adaptation state","title":"Adaptive scaling Metropolis","text":"","category":"section"},{"location":"adapt/","page":"Adaptation state","title":"Adaptation state","text":"AdaptiveScalingMetropolis","category":"page"},{"location":"adapt/#AdaptiveMCMC.AdaptiveScalingMetropolis","page":"Adaptation state","title":"AdaptiveMCMC.AdaptiveScalingMetropolis","text":"r = AdaptiveScalingMetropolis(x0; kwargs)\nr = AdaptiveScalingMetropolis(x0, [acc_target, [scale, [step]]])\nr = AdaptiveScalingMetropolis(acc_target, scale, step)\n\nConstructor for AdaptiveScalingMetropolis state.\n\nArguments\n\nx0: The initial state vector (not used).\n\nKeyword arguments\n\nacc_target: Desired mean accept rate; default 0.44 for   univariate and 0.234 for multivariate.\nscale: Initial scaling; default 1.0.\nstep: Step size object; default PolynomialStepSize(0.66).\n\nIf s is RWMState, then proposal samples may be drawn calling  draw!(s, r) and adaptation is performed with adapt!(r, s, α).\n\n\n\n\n\n","category":"type"},{"location":"adapt/","page":"Adaptation state","title":"Adaptation state","text":"Adaptive scaling Metropolis (ASM) implements a version of adaptive scaling first suggested in the Andrieu and Robert, 2001 preprint, but the version implemented by AdaptiveMCMC.jl is due to Andrieu and Thoms, 2008 and Atchadé and Fort, 2010.","category":"page"},{"location":"adapt/","page":"Adaptation state","title":"Adaptation state","text":"In the ASM, the adaptation parameter S_k is a scalar, and it has the following dynamic:","category":"page"},{"location":"adapt/","page":"Adaptation state","title":"Adaptation state","text":"log S_k = log S_k-1  + gamma_k (alpha_k - alpha_*)","category":"page"},{"location":"adapt/","page":"Adaptation state","title":"Adaptation state","text":"The update has similarities with RAM, which may be regarded as a multivariate generalisation of this rule.","category":"page"},{"location":"adapt/#Adaptive-scaling-within-adaptive-Metropolis","page":"Adaptation state","title":"Adaptive scaling within adaptive Metropolis","text":"","category":"section"},{"location":"adapt/","page":"Adaptation state","title":"Adaptation state","text":"AdaptiveScalingWithinAdaptiveMetropolis","category":"page"},{"location":"adapt/#AdaptiveMCMC.AdaptiveScalingWithinAdaptiveMetropolis","page":"Adaptation state","title":"AdaptiveMCMC.AdaptiveScalingWithinAdaptiveMetropolis","text":"r = AdaptiveScalingWithinAdaptiveMetropolis(x0; kwargs)\nr = AdaptiveScalingWithinAdaptiveMetropolis(x0, [acc_target, \n      [scale, [stepAM, [stepASM]]]])\n\nConstructor for AdaptiveScalingWithinAdaptiveMetropolis state.\n\nArguments\n\nx0: The initial state vector.\n\nKeyword arguments\n\nacc_target: Desired mean accept rate; default 0.234.\nscale: Initial scaling; default 2.38/sqrt(d) where d is the dimension.\nstepAM: Step size object for covariance adaptation;            default PolynomialStepSize(0.66).\nstepASM: Step size object for scaling adaptation;            default PolynomialStepSize(0.66).\n\nIf s is RWMState, then proposal samples may be drawn calling  draw!(s, r) and adaptation is performed with adapt!(r, s, α) or  adapt_rb!(r, s, α).\n\n\n\n\n\n","category":"type"},{"location":"adapt/","page":"Adaptation state","title":"Adaptation state","text":"The adaptive scaling within adaptive Metropolis combines the AM and ASM, as suggested (at least) in  Andrieu and Thoms, 2008. That is:","category":"page"},{"location":"adapt/","page":"Adaptation state","title":"Adaptation state","text":"The scaling theta_k is updated as in the ASM\nThe covariance Sigma_k is updated as in AM, with Cholesky factor L_k\nThe scaling parameter is both combined: S_k = theta_k L_k","category":"page"},{"location":"adapt/","page":"Adaptation state","title":"Adaptation state","text":"This algorithm is often more robust than AM, but often outperformed by a simpler RAM.","category":"page"},{"location":"adapt/#'Rao-Blackwellised'-update","page":"Adaptation state","title":"'Rao-Blackwellised' update","text":"","category":"section"},{"location":"adapt/","page":"Adaptation state","title":"Adaptation state","text":"The covariance states of AdaptiveMetropolis and AdaptiveScalingWithingAdaptiveMetropolis also support the alternative adaptation suggested in Andrieu and Thoms, 2008. The alternative update call is the following:","category":"page"},{"location":"adapt/","page":"Adaptation state","title":"Adaptation state","text":"adapt_rb!","category":"page"},{"location":"adapt/#AdaptiveMCMC.adapt_rb!","page":"Adaptation state","title":"AdaptiveMCMC.adapt_rb!","text":"adapt_rb!(s, r, α)\n\nRao-Blackwellised adaptation step of Adaptive Metropolis as suggested by Andrieu & Thoms (Statist. Comput. 2008).\n\nArguments:\n\ns: AdaptiveMetropolis object\nr: RWMState object\nα: Acceptance rate\n\nNB: This function should be called before calling accept!(r).\n\n\n\n\n\n","category":"function"},{"location":"adapt/","page":"Adaptation state","title":"Adaptation state","text":"This update is not based on new, accepted state, but involves a convex combination of the current and proposed states, weighted by the acceptance probability:","category":"page"},{"location":"adapt/","page":"Adaptation state","title":"Adaptation state","text":"beginaligned\nmu_k = (1-gamma_k)mu_k-1 + gamma_k big(1-alpha_k) X_k-1 + alpha_k Y_kbig \nSigma_k = (1-gamma_k)Sigma_k-1 + gamma_k big(1-alpha_k)(X_k-1 - mu_k-1)(X_k-1 - mu_k-1)^T + alpha_k (Y_k - mu_k-1)(Y_k - mu_k-1)^Tbig\nendaligned","category":"page"},{"location":"adapt/","page":"Adaptation state","title":"Adaptation state","text":"This update is 'Rao-Blackwellised' in the sense that it may be regarded as a conditional expectation of the AM adaptation rule, integrating the accept/reject decision. The Rao-Blackwellised rule can stabilise the covariance adaptation slightly.","category":"page"},{"location":"#Introduction","page":"Introduction","title":"Introduction","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"This package provides implementations of some general-purpose random-walk based adaptive MCMC algorithms, including the following:","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"Adaptive Metropolis, proposal covariance adaptation, (Haario, Saksman and Tamminen, 2001, and Andrieu and Moulines, 2006)\nAdaptive scaling Metropolis, acceptance rate adaptation for scale (e.g. as in Andrieu and Thoms, 2008, and Atchadé and Fort, 2010)\nRobust Adaptive Metropolis, acceptance rate adaptation for shape (Vihola, 2012)\nAdaptive Parallel Tempering, acceptance rate adaptation for temperature levels (Miasojedow, Moulines and Vihola, 2013)","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"The aim of the package is to provide a simple and modular general-purpose implementation, which may be easily used to sample from a log-target density, but also used in a variety of custom settings.","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"See also AdaptiveParticleMCMC.jl which uses this package with SequentialMonteCarlo.jl for adaptive particle MCMC.","category":"page"},{"location":"#Installation","page":"Introduction","title":"Installation","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"To get the latest registered version:","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"using Pkg\nPkg.add(\"AdaptiveMCMC\")","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"To install the latest development version:","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"using Pkg\nPkg.add(url=\"https://github.com/mvihola/AdaptiveMCMC.jl\")","category":"page"},{"location":"#Sampling-from-log-posteriors","page":"Introduction","title":"Sampling from log-posteriors","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"The package provides an easy-to-use adaptive random-walk Metropolis sampler, which samples (in principle) from any probability distribution p, whose log-density values can be evaluated point-wise.","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"# Load the package\nusing AdaptiveMCMC\n\n# Define a function which returns log-density values:\nlog_p(x) = -.5*sum(x.^2)\n\n# Run 10k iterations of the Adaptive Metropolis:\nout = adaptive_rwm(zeros(2), log_p, 10_000; algorithm=:am)\n\n# Calculate '95% credible intervals':\nusing Statistics\nmapslices(x->\"$(mean(x)) ± $(1.96std(x))\", out.X, dims=2)","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"See Adaptation state for explanation of the different algorithm options:","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":":am = AdaptiveMetropolis\n:ram = RobustAdaptiveMetropolis\n:asm = AdaptiveScalingMetropolis\n:aswam = AdaptiveScalingWithinAdaptiveMetropolis","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"There are a number of other optional keyword arguments, too:","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"adaptive_rwm","category":"page"},{"location":"#AdaptiveMCMC.adaptive_rwm","page":"Introduction","title":"AdaptiveMCMC.adaptive_rwm","text":"out = adaptive_rwm(x0, log_p, n; kwargs)\n\nGeneric adaptive random walk Metropolis algorithm from initial state vector x0 targetting log probability density log_p run for n iterations, including adaptive parallel tempering.\n\nArguments\n\nx0::Vector{<:AbstractFloat}: The initial state vector\nlog_p::Function: Function that returns log probability density values                    (up to an additive constant) for any state vector.\nn::Int: Total number of iterations\n\nKeyword arguments\n\nalgorithm::Symbol: The random walk adaptation algorithm; current choices are :ram (default), :am, :asm, :aswam and :rwm. (Alternatively, if algorithm is a vector of AdaptState, then this will be used as an initial state for adaptation.)\nb::Int: Burn-in length: b:th sample is the first saved sample. Default ⌊n/5⌋\nthin::Int: Thinning factor; only every thin:th sample is stored; default 1\nfulladapt::Bool: Whether to adapt after burn-in; default true\nSp: Saved adaptive state from output to restart MCMC; default nothing\nRp: Saved rng state from output to restart MCMC; default nothing\n'indp: Index of saved adaptive state to restart MCMC; default0`\nrng::AbstractRNG: Random number generator; default Random.GLOBAL_RNG\nq::Function: Zero-mean symmetric proposal generator (with arguments x and rng);  default q=randn!(x, rng)\nL::Int: Number of parallel tempering levels\nacc_sw::AbstractFloat: Desired acceptance rate between level swaps; default 0.234\nall_levels::Bool: Whether to store output of all levels; default false\nlog_pr::Function: Log-prior density function; default log_pr(x) = 0.0.\nswaps::Symbol: Swap strategy, one of:  :single (default, single randomly picked swap)  :randperm (swap in random order)  :sweep (up- or downward sweep, picked at random)  :nonrev (alternate even/odd sites as in Syed, Bouchard-Côté, Deligiannidis,  Doucet, \tarXiv:1905.02939)\n\nNote that if log_pr is supplied, then log_p(x) is regarded as the log-likelihood (or, equivalently, log-target is log_p(x) + log_pr(x)). Tempering is only applied to log_p, not to log_pr.\n\nThe output out.X contains the simulated samples (column vectors).out.allX[k]fork>=2` contain higher temperature auxiliary chains (if requested)\n\nExamples\n\nlog_p(x) = -.5*sum(x.^2)\no = adaptive_rwm(zeros(2), log_p, 10_000; algorithm=:am)\nusing MCMCChains, StatsPlots # Assuming MCMCChains & StatsPlots are installed...\nc = Chains(o.X[1]', start=o.params.b, thin=o.params.thin); plot(c)\n\n\n\n\n\n","category":"function"},{"location":"#With-adaptive-parallel-tempering","page":"Introduction","title":"With adaptive parallel tempering","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"If the keyword argument L is greater than one, then the adaptive parallel tempering algorithm (APT) of Miasojedow, Moulines & Vihola (2013) is used. This can greatly improve mixing with multimodal distributions.","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"Here is a simple multimodal distribution sampled with normal adaptive random walk Metropolis, and with APT:","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"# Multimodal target of dimension d.\nfunction multimodalTarget(d::Int, sigma2=0.1^2, sigman=sigma2)\n    # The means of mixtures\n    m = [2.18 5.76; 3.25 3.47; 5.41 2.65; 4.93 1.50; 8.67 9.59;\n         1.70 0.50; 2.70 7.88; 1.83 0.09; 4.24 8.48; 4.59 5.60;\n         4.98 3.70; 2.26 0.31; 8.41 1.68; 6.91 5.81; 1.14 2.39;\n         5.54 6.86; 3.93 8.82; 6.87 5.40; 8.33 9.50; 1.69 8.11]'\n    n_m = size(m,2)\n    @assert d>=2 \"Dimension should be >= 2\"\n    let m=m, n_m=size(m,2), d=d\n        function log_p(x::Vector{Float64})\n            l_dens = -0.5*(mapslices(sum, (m.-x[1:2]).^2, dims=1)/sigma2)\n            if d>2\n                l_dens .-= 0.5*mapslices(sum, x[3:d].^2, dims=1)/sigman\n            end\n            l_max = maximum(l_dens) # Prevent underflow by log-sum trick\n            l_max + log(sum(exp.(l_dens.-l_max)))\n        end\n    end\nend\n\nusing AdaptiveMCMC\nn = 100_000; L = 2\nrwm = adaptive_rwm(zeros(2), multimodalTarget(2), n; thin=10)\napt = adaptive_rwm(zeros(2), multimodalTarget(2), div(n,L); L = L, thin=10)\n\n# Assuming you have 'Plots' installed:\nusing Plots\nplot(scatter(rwm.X[1,:], rwm.X[2,:], title=\"w/o tempering\", legend=:none),\nscatter(apt.X[1,:], apt.X[2,:], title=\"w/ tempering\", legend=:none), layout=(1,2))","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"What the APT is actually based on? Parallel tempering is a MCMC algorithm which samples from a product density proporitional to:","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"prod_i=1^L p^beta(i)(x^(i))","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"where (the 'inverse temperatures') 1 = beta(1)  beta(2)  cdots  beta(L)  0.","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"In the end, the 'first level' is of interest (and samples of the first level are usually used for estimation), whereas the tempered levels i=2ldotsL are auxiliary, which help the sampler to move between modes of a multi-modal target. The easier moving is because the tempered densities p^beta(i) are 'flatter' than p for any beta(i)1.","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"The sampler consists of two types of MCMC moves:","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"Independent adaptive random-walk Metropolis moves on individual levels i, targetting tempered densities p^beta(i). \nSwitch moves, where swaps of adjacent levels x^(i) leftrightarrow x^(i+1) are proposed, and the moves are accepted with (Metropolis-Hastings) probability minbig1 fracp^beta(i)-beta(i+1)(x^(i+1))p^beta(i)-beta(i+1)(x^(i))big.","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"In the APT, each random walk sampler for each individual level is adapted totally independently, following exactly the same mechanism as before. Additionally, the APT adapts the inverse temperatures beta(2)ldotsbeta(L), in order to reach the average switch probability 0234. More precisely, adaptation mechanism tunes the parameters rho^(i), which determine","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"frac1beta^(i) = frac1beta^(i-1) + e^rho^(i)","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"and the adaptation is similar to Adaptive scaling Metropolis: if swap x^(i-1)leftrightarrow x^(i) is proposed the k:th time, the parameter is updated as follows:","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"rho_k^(i) = rho_k-1^(i) + gamma_k (alpha_k^(textswap i) - alpha_*)","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"where alpha_k^(textswap i) is the swap probability.","category":"page"},{"location":"#Restarting-simulation","page":"Introduction","title":"Restarting simulation","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"Simulation can be restarted, or continued after one simulation. Here is an example:","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"using AdaptiveMCMC, Random\nlog_p(x) = -.5*sum(x.^2)\nRandom.seed!(12345)\n# Simulate 200 iterations first:\nout = adaptive_rwm(zeros(2), log_p, 200)\n# Simulate 100 iterations more:\nout2 = adaptive_rwm(out.X[:,end], log_p, 100; Sp=out.S, Rp=out.R, indp=200)\n# This results in exactly the same output as simulating 300 samples in one go:\nRandom.seed!(12345)\nout2_ = adaptive_rwm(zeros(2), log_p, 300)","category":"page"},{"location":"#Using-individual-modules-in-a-custom-setting","page":"Introduction","title":"Using individual modules in a custom setting","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"In many cases, the simple samplers provided by adaptive_rwm are not sufficient, but a custmised sampler is necessary. For instance:","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"Adaptative sampler is used only for certain parameters, whilst others are updated by another MCMC scheme, such as with Gibbs moves.\nThe sampler state is large, and simulations cannot be saved in memory.","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"The package provides simple building blocks which allow such custom scenarios. Here is a simple example how the individual components can be used:","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"using AdaptiveMCMC\n\n# Sampler in R^d\nfunction mySampler(log_p, n, x0)\n\n    # Initialise random walk sampler state: r.x current state, r.y proposal\n    r = RWMState(x0)\n\n    # Initialise Adaptive Metropolis state (with default parameters)\n    s = AdaptiveMetropolis(x0)\n    # Other adaptations are: AdaptiveScalingMetropolis,\n    # AdaptiveScalingWithinAdaptiveMetropolis, and RobustAdaptiveMetropolis\n\n    X = zeros(eltype(x0), length(x0), n) # Allocate output storage\n    p_x = log_p(r.x)                     # = log_p(x0); the initial log target\n    for k = 1:n\n\n        # Draw new proposal r.x -> r.y:\n        draw!(r, s)\n\n        p_y = log_p(r.y)                      # Calculate log target at proposal\n        alpha = min(one(p_x), exp(p_y - p_x)) # The Metropolis acceptance probability\n\n        if rand() <= alpha\n            p_x = p_y\n\n            # This 'accepts', or interchanges r.x <-> r.y:\n            # (NB: do not do r.x = r.y; these are (pointers to) vectors!)\n            accept!(r)\n        end\n\n        # Do the adaptation update:\n        adapt!(s, r, alpha, k)\n\n        X[:,k] = r.x   # Save the current sample\n     end\n    X\nend\n\n# Standard normal target for testing\nnormal_log_p(x) = -mapreduce(e->e*e, +, x)/2\n\n# Run 1M iterations of the sampler targetting 30d standard Normal:\nX = mySampler(normal_log_p, 1_000_000, zeros(30))","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"See Random-walk sampler state and Adaptation state for more details about these components.","category":"page"},{"location":"rwm/#Random-walk-sampler-state","page":"Random walk sampler state","title":"Random-walk sampler state","text":"","category":"section"},{"location":"rwm/","page":"Random walk sampler state","title":"Random walk sampler state","text":"The state of a random-walk Metropolis sampler is encapsulated in the data structure RWMState, which can be constructed as follows:","category":"page"},{"location":"rwm/","page":"Random walk sampler state","title":"Random walk sampler state","text":"RWMState","category":"page"},{"location":"rwm/#AdaptiveMCMC.RWMState","page":"Random walk sampler state","title":"AdaptiveMCMC.RWMState","text":"s = RWMState(x0, [rng, [q!]])\n\nConstructor for RWMState (random walk Metropolis state).\n\nArguments\n\nx0: The initial state vector\nrng: Random number generator; default Random.GLOBAL_RNG.\nq!: Symmetric proposal distribution; default randn!. Called by q!(rng, u) which puts a draw to vector u\n\nIf s is RWMState, then s.x is the current state. New proposal may be drawn to s.y by calling draw!, and the proposal is accepted by calling accept!(s).\n\n\n\n\n\n","category":"type"},{"location":"rwm/","page":"Random walk sampler state","title":"Random walk sampler state","text":"By default, the RWMState will provide a Gaussian random walk sampler, as the 'prototype' increment proposal density q! corresponds to a standard normal N(0I). The increment proposal density can be any other distribution, as long as it is symmetric: it is as likely to produce a random vector z as it is to produce -z.","category":"page"},{"location":"rwm/#Forming-a-proposal","page":"Random walk sampler state","title":"Forming a proposal","text":"","category":"section"},{"location":"rwm/","page":"Random walk sampler state","title":"Random walk sampler state","text":"Assuming s=RWMState, we can use two methods. The first is draw!, which forms a proposal. This means that starting from X_k-1=s.x, we produce","category":"page"},{"location":"rwm/","page":"Random walk sampler state","title":"Random walk sampler state","text":"Y_k sim X_k-1 + C U_k quad U_k sim q","category":"page"},{"location":"rwm/","page":"Random walk sampler state","title":"Random walk sampler state","text":"where q corresponds to the distribution s.q! simulates from. The increment vector U_k is stored to an internal s.u (which is used by some of the adaptive algorithms), and the proposal Y_k is stored to s.y.","category":"page"},{"location":"rwm/","page":"Random walk sampler state","title":"Random walk sampler state","text":"The factor C in the update is not part of the RWMState structure, but supplied as a parameter to the function draw!. It can be a scalar, which controls the increment scale, or a scalar times Cholesky factor, which controls the shape of the increment distribution.","category":"page"},{"location":"rwm/","page":"Random walk sampler state","title":"Random walk sampler state","text":"draw!","category":"page"},{"location":"rwm/#AdaptiveMCMC.draw!","page":"Random walk sampler state","title":"AdaptiveMCMC.draw!","text":"draw!(s::RWMState, sc::AbstractFloat)\n\nDraw proposal from s.x to s.y using scaling sc.\n\n\n\n\n\ndraw!(s::RWMState, L::Cholesky, sc::AbstractFloat)\n\nDraw proposal from s.x to s.y using scaling sc*L.L, with default sc=1.0.\n\n\n\n\n\n","category":"function"},{"location":"rwm/#Forming-a-proposal-with-adaptive-state","page":"Random walk sampler state","title":"Forming a proposal with adaptive state","text":"","category":"section"},{"location":"rwm/","page":"Random walk sampler state","title":"Random walk sampler state","text":"Calling draw(r::RWMState, s::AdaptState), where s is one of the Adaptation state will use the adapted scale/shape when forming the proposal.","category":"page"},{"location":"rwm/#Accepting-a-proposal","page":"Random walk sampler state","title":"Accepting a proposal","text":"","category":"section"},{"location":"rwm/","page":"Random walk sampler state","title":"Random walk sampler state","text":"After draw!, the state s.x and the proposal s.y can be accessed (and for instance copied to storage), but should not be modified directly. Instead, the 'acceptance', which means that s.y will replace s.x should be done as follows:","category":"page"},{"location":"rwm/","page":"Random walk sampler state","title":"Random walk sampler state","text":"accept!","category":"page"},{"location":"rwm/#AdaptiveMCMC.accept!","page":"Random walk sampler state","title":"AdaptiveMCMC.accept!","text":"accept!(s::RWMState)\n\nAccept the proposal, that is, set copy s.y to s.x.\n\n\n\n\n\n","category":"function"}]
}
